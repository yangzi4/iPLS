from sklearn.linear_model import LogisticRegression
from sklearn import svm
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
import os
from math import factorial
 
## ___simulation #1___
def iPLS_sim(u_error, nrep, prop=0.05, BS=0, link_='identity', PLS_type_='pred',
    N_DIR=1, store_w=0, LL=[10**x for x in arange(-1.5, 1.5, 0.5)]):
    DD = range(1, 5)
     
    K = len(Xs_dims_EX)
    N_imp = N_total
    val1 = zeros((0, shift))
    val2 = zeros((0, 5*(2**K - 1)))
    rep = 0
    ws = [zeros((Xs_dims_EX[0][1], 0)) for i in range(5)]
    while rep < nrep:
        train_Xs, train_Ys, true_Bs, tr_idcs = sup_data_gen(Xs_dims_EX, q_EX,
            Bs_main_EX, u_error, Bs1=BS, link=link_)
        train_X_full, train_Y_full = vstack(train_Xs), vstack(train_Ys)
         
        worked = 1
        while worked > 0 and worked != 5:
            try:
                K = len(train_Xs)  ## sPLS
                Ds_ch = [PLS_CV(train_Xs[k], train_Ys[k], D_list=DD, PLS_type=PLS_type_)
                    for k in range(K)]
                plsMth_S_res = []
                for k in range(K):
                    if PLS_type_ == 'pred': plsMth = PLSRegression(n_components=Ds_ch[k][0])
                    if PLS_type_ == 'infr': plsMth = PLSCanonical(n_components=Ds_ch[k][0])
                    plsMth_S_res.append(plsMth.fit(train_Xs[k], train_Ys[k]))
                D_ch2 = PLS_CV(train_X_full, train_Y_full, D_list=DD, PLS_type=PLS_type_)  ## jPLS
                if PLS_type_ == 'pred': plsMth = PLSRegression(n_components=D_ch2[0])
                if PLS_type_ == 'infr': plsMth = PLSCanonical(n_components=D_ch2[0])
                plsMth_res = plsMth.fit(train_X_full, train_Y_full)
                D_ch, L_ch, DL_AUCs = iPLS_CV(train_Xs, train_Ys, D_list=DD, L_list=LL)  ## iPLS
                #if L_ch == LL[0]: iPLS_res_ = plsMth_S_res
                #if L_ch == LL[-1]: iPLS_res_ = plsMth_res
                iPLS_res = iPLS_run(train_Xs, train_Ys, D_ch, L_ch)
                worked *= 0
            except (linalg.LinAlgError, ValueError): worked += 1
        if worked == 5: continue
         
        if store_w == 1:
            ws[0] = hstack((ws[0], train_Xs[0].T.dot(train_Ys[0])))
            ws[1] = hstack((ws[1], train_Xs[1].T.dot(train_Ys[1])))
            ws[2] = hstack((ws[2], train_X_full.T.dot(train_Y_full)))
            if rep == nrep - 1: save("ws(D1-r)_%d(2)x%d,%d(%d)_%d-%d" % (Xs_dims_EX[0][0],
                Xs_dims_EX[0][1], N_total, N_comm, u_e*100, s_e*100), ws)  ## pxnrep, x3
         
        if q_EX == 1:
            LR_res = lr.fit(train_X_full, train_Y_full[:, 0])
            SVM_res = linSVC.fit(train_X_full, train_Y_full[:, 0])
            RF_res = RForest.fit(train_X_full, train_Y_full[:, 0])
        #else: 
        #    SVM_res = linSVC.fit(train_X_full, train_Y_full)
        #    RF_res = RForest.fit(train_X_full, train_Y_full)
         
        ## prediction
        pred_trials = []
        worked = 1
        while worked > 0 and worked != 5:
            try:
                for trial in range(100):
                    test_Xs, test_Ys, true_Bs, tr_idcs = sup_data_gen(Xs_dims_EX,
                        q_EX, Bs_main_EX, u_error, true_Bs, Bs1=BS,
                        link=link_)
                    test_X_full, test_Y_full = vstack(test_Xs), vstack(test_Ys)
                     
                    if L_ch == LL[0]: iPLS_AUC = gmean([auc_calc(plsMth_S_res[k].predict(test_Xs[k]), test_Ys[k]) for k in
                        range(len(test_Xs))])
                    elif L_ch == LL[-1]:
                        iPLS_AUC = auc_calc(plsMth_res.predict(test_X_full), test_Y_full)
                    else: iPLS_AUC = gmean([auc_calc(iPLS_pred(test_Xs, iPLS_res[0], iPLS_res[1], iPLS_res[2],
                        separate=1, norm_params=iPLS_res[3])[k], test_Ys[k]) for k in range(K)])
                     
                    if q_EX == 1:
                        LR_AUC = auc_calc(LR_res.predict_proba(test_X_full)[:, 1:], test_Y_full)
                        SVM_AUC = auc_calc(SVM_res.predict_proba(test_X_full)[:, 1:], test_Y_full)
                        RF_AUC = auc_calc(RF_res.predict_proba(test_X_full)[:, 1:], test_Y_full)
                    else:
                        RF_AUC = auc_calc(hstack([RF_res.predict_proba(test_X_full)[q][:, 1:]
                            for q in range(shape(test_Y_full)[1])]), test_Y_full)
                        SVM_AUC = RF_AUC#auc_calc(SVM_res.predict_proba(test_X_full), test_Y_full)
                    pred_trials.append([
                        auc_calc(vstack([plsMth_S_res[k].predict(test_Xs[k]) for k in
                            range(len(test_Xs))]), vstack(test_Ys)),
                        auc_calc(vstack(iPLS_pred(test_Xs, iPLS_res[0], iPLS_res[1], iPLS_res[2],
                            separate=1, norm_params=iPLS_res[3])), vstack(test_Ys)),
                        auc_calc(plsMth_res.predict(test_X_full), test_Y_full),
                         
                        LR_AUC,
                        SVM_AUC,
                        RF_AUC
                        ])
                    worked *= 0
            except linalg.LinAlgError:
                print 'Pred: LinAlgError'
                worked += 1
        if worked == 5 or sum(array(pred_trials)) == nan: continue
        val1 = vstack((val1, mean(array(pred_trials), 0)))
         
        ## inference
        N_imp_ = [8, 8]#list(fmax(array([len(tr_idcs[0][0]), len(tr_idcs[-1][0])]), 1))
        s_groups_ = intg_rankings([plsMth_S_res[k].x_weights_ for k in range(K)], N_imp_, N_DIR)
        s_groups = [s_groups_[0]]*1 + [s_groups_[0] + s_groups_[0]]*2 + [s_groups_[0]] + [s_groups_[-1]]#3 3 1 or 5 10 10 5 1
        s_n_matches = [num_common(s_groups[k], tr_idcs[k]) for k in range(K)]
        j_groups_ = intg_rankings([plsMth_res.x_weights_]*K, N_imp_, N_DIR)
        j_groups = [j_groups_[0]]*1 + [j_groups_[0] + j_groups_[0]]*2 + [j_groups_[0]] + [j_groups_[-1]]#
        j_n_matches = [num_common(j_groups[k], tr_idcs[k]) for k in range(K)]
        if L_ch == LL[0] and 0:
            i_n_matches = [[s_n_matches[k][i] for i in range(len(s_n_matches[k]))]
                for k in range(K)]
        elif L_ch == LL[-1] and 0:
            i_n_matches = [[j_n_matches[k][i] for i in range(len(j_n_matches[k]))]
                for k in range(K)]
        else:
            i_groups_ = intg_rankings(iPLS_res[0], N_imp_, N_DIR)
            i_groups = [i_groups_[0]]*1 + [i_groups_[0] + i_groups_[0]]*2 + [i_groups_[0]] + [i_groups_[-1]]#
            i_n_matches = [num_common(i_groups[k], tr_idcs[k]) for k in range(K)]
        rf_groups_ = [[argsort(RF_res.feature_importances_)[::-1][:N_imp_[1]]]*K]
        rf_groups = [rf_groups_[0]]*1 + [rf_groups_[0] + rf_groups_[0]]*2 + [rf_groups_[0]] + [[rf_groups_[0][0]]]#
        rf_n_matches = [num_common(rf_groups[k], tr_idcs[k]) for k in range(K)]
        lr_groups_ = [[argsort(LR_res.coef_[0, :])[::-1][:N_imp_[1]]]*K]
        lr_groups = [lr_groups_[0]]*1 + [lr_groups_[0] + lr_groups_[0]]*2 + [lr_groups_[0]] + [[lr_groups_[0][0]]]#
        lr_n_matches = [num_common(lr_groups[k], tr_idcs[k]) for k in range(K)]
        clus_accr = []
        for k in range(K): clus_accr = clus_accr + s_n_matches[k]
        for k in range(K): clus_accr = clus_accr + i_n_matches[k]
        for k in range(K): clus_accr = clus_accr + j_n_matches[k]
        for k in range(K): clus_accr = clus_accr + lr_n_matches[k]
        for k in range(K): clus_accr = clus_accr + rf_n_matches[k]
        val2 = vstack((val2, clus_accr))
         
        rep += 1
        #print "__________repetition: " + str(rep)
        print [Ds_ch[k][0] for k in range(K)], D_ch2[0], D_ch, L_ch
        print val1[-1, :], 'rep', rep
        print val2[-1, :], 'rep', rep
    res_array = hstack((vstack([mean(val1, 0), std(val1, 0)]),
        vstack([mean(val2, 0), std(val2, 0)])))
    print mean(val1, 0), mean(val2, 0)
    return res_array  ## 2x 8
 
 
## _____
 
os.chdir('')#addr#
 
#Xs_dims_EX, q_EX = [(100, 500)]*2, 1
#Xs_dims_EX, q_EX = [(100, 100), (100, 100), (30, 100)], 1
Xs_dims_EX, q_EX = [(100, 200)]*3, 1
#Xs_dims_EX, q_EX = [(50, 100), (150, 100)], 1
#Xs_dims_EX, q_EX = [(200, 600)]*2, 1
#Xs_dims_EX, q_EX = [(60, 200)]*5, 1
#Xs_dims_EX, q_EX = [(60, 300), (120, 300), (180, 300)], 1
K = len(Xs_dims_EX)
lr = LogisticRegression()
linSVC = svm.SVC(kernel='rbf', probability=1)
RForest = RandomForestClassifier()
N_total = 8
shift = 6  ## 6
 
vers = '()'
i_range = range(0, 9, 2)
for i in i_range:
    random.seed(1)
    N_comm = i
    N_c = N_total - N_comm
    #Bs_main_EX = [[N_c]*2, [N_comm]]  ## change
    #Bs_main_EX = [[N_c]*3, [0]*3, [N_comm]]  ## change
    Bs_main_EX = [[N_c]*K, [0]*2*K, [0]*2*K, [0]*K, [N_comm]]  ## change
    u_e = 0.1
    sim_results = iPLS_sim(u_e, 50, BS=-1, link_='identity',
        N_DIR=1, store_w=0)  ## change
    save("iPLS%s_i-p(50rep)_%d(%d)x%d-%d,%d(%d)_%d,1-4_Ls1-100j" % (vers,
        Xs_dims_EX[0][0], K, Xs_dims_EX[0][1], q_EX, N_total, N_comm, u_e*100), sim_results)
 
#vers = '()'
plot_array = []
plot_array2 = []
for N_comm in i_range:
    #N_comm = min(N_comm, 2)
    for u_e in [0.1]:
        res = load("iPLS%s_i-p(50rep)_%d(%d)x%d-%d,%d(%d)_%d,1-4_Ls1-100j.npy" %
            (vers, Xs_dims_EX[0][0], K, Xs_dims_EX[0][1], q_EX, N_total, N_comm,
            u_e*100))
        print around(res[0, :], 2)
        plot_array.append(res[0, :])
        plot_array2.append(res[1, :])
plot_array = array(plot_array)
plot_array2 = array(plot_array2)
 
mat1, mat2 = [], []
clrs = ['b', 'c', 'r', 'k', 'm', 'g']
l_styles = ['-', '-', '-', '-', '-', '-']
plt.figure()
for method in range(shift):
    plt.errorbar(i_range, plot_array[:, method], yerr=plot_array2[:, method]/sqrt(50),
        ls=l_styles[method], color=clrs[method])
    mat1.append(plot_array[:, method])
plt.legend(['sPLS', 'iPLS', 'jPLS', 'LReg', 'GaussSVM', 'RForest'], loc='lower right',
    fontsize=12)
plt.xlabel('# of overlapping causal variables')
plt.title('AUCs%s, 1-4_Ls1-100j, dim%d(%d)_%d-%d_%d' % (vers, Xs_dims_EX[0][0], K,
    Xs_dims_EX[0][1], q_EX, u_e*100))
plt.savefig('AUCs%s,_1-4_Ls1-100j,_dim%d(%d)_%d-%d_%d.png' % (vers, Xs_dims_EX[0][0], K,
    Xs_dims_EX[0][1], q_EX, u_e*100), format="png", dpi=150, bbox_inches='tight')
 
method_names = ['sPLS', 'iPLS', 'jPLS', 'LReg', 'RForest']#
grp_list = []
for k in range(K): grp_list = grp_list + [k]*int(math.factorial(K)/float(
    math.factorial(k + 1)*math.factorial(K - k - 1)))
group_names = ['%d comm' % g_num for g_num in grp_list]
clrs = ['b', 'c', 'r', 'k', 'g']#
l_s = ['--']*K
l_s[0] = ':'
l_s[-1] = '-'
l_styles = [l_s[g_num] for g_num in grp_list]
plt.figure(figsize=(9, 6))
for method in range(5):#
    for group in range(2**K - 1):
        plt.errorbar(i_range, plot_array[:, (2**K - 1)*method+group+shift],
            yerr=plot_array2[:, (2**K - 1)*method+group+shift]/sqrt(50), ls=l_styles[group],
            color=clrs[method], label='%s (%s)' % (method_names[method], group_names[group]))
        mat2.append(plot_array[:, (2**K - 1)*method+group+shift])
print around(array(mat1).T, 2)
print around(array(mat2).T, 1)[:, [6, 13, 20, 27, 34]]#[2, 5, 8, 11, 14], [6, 13, 20, 27, 34], [30, 61, 92, 123, 154]
print around(mean(array(mat2).T[:, 0:3], 1), 1), around(mean(array(mat2).T[:, 7:10], 1), 1)
K_const = 2**K - 1
for method_ in range(5):  ## s i j lr rf
    #print around(array(mat2).T[:, (method_*K_const):((method_+1)*K_const)], 1)
    print around(array(mat2).T[:, (method_*K_const + 6):(method_*K_const + 7)], 1).T
    print around(mean(array(mat2).T[:, (method_*K_const):(method_*K_const + 3)], axis=1), 1)
#for g in range(1, 3):
#    plt.errorbar(arange(0, 9, 2), group_mems[g], ls=l_styles[g],
#        color='k', label='truth (%s)' % group_names[g])
plt.xlim(0, 10.6)
plt.ylim(-0.25, 8.25)#amax(plot_array[:, shift:]) + 0.5)
plt.legend(loc='upper right', fontsize=10)
plt.xlabel('# of overlapping causal variables')
plt.title('number of identified causal variables%s, %dtotal(top%d), dim%d(%d)_%d-%d_%d'
    % (vers, N_total, N_total, Xs_dims_EX[0][0], K, Xs_dims_EX[0][1], q_EX, u_e*100))
plt.savefig('number_identified%s,_%dtotal(top%d),_dim%d(%d)_%d-%d_%d.png'
    % (vers, N_total, N_total, Xs_dims_EX[0][0], K, Xs_dims_EX[0][1], q_EX, u_e*100),
    format="png", dpi=150, bbox_inches='tight')
